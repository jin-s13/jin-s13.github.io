
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Sheng Jin; Computer Vision; Deep Learning; Human Pose Estimation; The University of Hong Kong; Tsinghua University">
    <link rel="author" href="https://jin-s13.github.io/">
    <title>Sheng Jin's Homepage</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-177752133-1', 'https://jin-s13.github.io');
  ga('send', 'pageview');
</script>

<body>
    <div id="container">
        <div id="header">
            <h1><a href="#">Sheng Jin</a></h1>
            <br>
            <div class="clear"></div>
        </div>
        
        <div id="body">
            <div id="aboutme">
                <h2>About Me</h2>
                <table class="table-bio">
                    <td class="col-7">
                    <p>
                        Sheng Jin is currently a Phd student (2020-present) at the University of Hong Kong (HKU), advised by Dr. <a href="http://luoping.me/">Ping Luo</a> and co-supervised by Prof. <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a> and Prof. <a href="https://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>. 
                        <br>
                        <br>
                        In 2020, he received his master's degree in the Department of Automation at Tsinghua University, advised by Prof. <a href="https://scholar.google.com/citations?user=GL9M37YAAAAJ&hl=en">Changshui Zhang</a>.
                        In 2017, he received the B.Eng. degree with highest honor (Outstanding Graduate Scholarships) from Tsinghua University.
                        <br>
                        <br>
                        His research focus is on teaching machines/robots to see and understand human behaviors such as human body poses, actions, and human-machine interactions.
                    </p>
                    </td>
                    <td class="col-3">
                        <img src="./homepage_files/me.png">
                    </td>
                </table>
            </div>

            
            <div id="news">
                <h2>News</h2>
                <br>
                    <ul>
                        <li>[2022-07] Three papers have been accepted to ECCV'2022 (1 <font color="#e86e14">Oral</font> and 2 Posters).</li>
                        <br>
                        <li>[2022-04] One paper accepted to CVPR'2022 <font color="#e86e14">(Oral)</font>.</li>
                        <br>
                        <li>[2022-01] One paper accepted to ICLR'2022.</li>
                        <br>
                        <li>[2021-07] One paper accepted to ICCV'2021.</li>
                        <br>
                        <li>[2021-03] Two papers accepted to CVPR'2021.</li>
                    </ul>
            </div>

            <div id="education">
                <h2>Education</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/hku.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>The University of Hong Kong</h6>
                                <br>
                                PhD in Computer Science (HKPFS awardee), 2020~now
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/thu.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Tsinghua University</h6>
                                <br>
                                 MS in Control Science and Engineering, 2017~2020
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/thu.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Tsinghua University</h6>
                                <br>
                                BSc in Automation (ranking 1/145), 2013~2017
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <br>
            <br>

            <div class="container">
                <h2>Honors and Awards</h2>
                <div>
                    <ul>
                        <li>YS and Christabel Lung Postgraduate Scholarship, 2020-2021.</li>
                        <br>
                        <li>HKU Presidential PhD Scholarship (HKU-PS) 2020.</li>
                        <br>
                        <li><b>Hong Kong PhD Fellowships (HKPF)</b>, 2020.</li>
                        <br>
                        <li><b>Outstanding Graduate Scholarship</b>, Tsinghua University (top 1% in Tsinghua), 2017.</li>
                        <br>
                        <li><b>The Baosteel Excellent Student Scholarship</b>, 2016.</li>
                        <br>
                        <li>Zheng Weimin Scholarship (2nd class) for Comprehensive Excellence, 2016.</li>
                        <br>
                        <li>Tsinghua-JJWorld (Beijing) Nework Technology Fellowships, Tsinghua University, 2015.</li>
                        <br>
                        <li>Tsinghua-Evergrande Fellowships for Academic Excellence, Tsinghua University, 2014.</li>
                    </ul>
                </div>
            </div>
            
            <br>
            <br>

            <div id="publication">
                <h2>Selected Publications</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/CAPE-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Pose for Everything: Towards Category-Agnostic Pose Estimation</h6>
                                <br>
                                Lumin Xu*, <b>Sheng Jin</b>*, Wentao Liu, Chen Qian, Ping Luo, Wanli Ouyang, Xiaogang Wang
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2022, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="https://arxiv.org/abs/2207.10387.pdf">Paper</a>]&nbsp; [<a href="https://github.com/luminxu/Pose-for-Everything">Code & Data</a>] &nbsp;[<a href="https://mp.weixin.qq.com/s/8j3Zwk3f53XNSkDr56QT2A">Blog(商汤学术)</a>] 
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/PoseTrans-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>PoseTrans: A Simple Yet Effective Pose Transformation Augmentation for Human Pose Estimation</h6>
                                <br>
                                Wentao Jiang, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Ping Luo, Si Liu
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2022.</i>
                                <br><br>
                                [<a href="https://arxiv.org/pdf/2208.07755.pdf">Paper</a>]&nbsp; [<a href="https://github.com/wtjiang98/PoseTrans">Code</a>] 
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/HDR-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>3D Interacting Hand Pose Estimation by Hand De-occlusion and Removal</h6>
                                <br>
                                Hao Meng, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Mengxiang Lin, Wanli Ouyang, Ping Luo
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2022.</i>
                                <br><br>
                                [<a href="https://arxiv.org/abs/2207.11061">Paper</a>]&nbsp; [<a href="https://github.com/MengHao666/HDR">Code & Data</a>] 
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/TCFormer-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer</h6>
                                <br>
                                Wang Zeng, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Ping Luo, Ouyang Wanli, Xiaogang Wang
                                <br>
                                <br>
                                <i>Conference on Computer Vision and Pattern Recognition (CVPR), 2022, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="https://arxiv.org/pdf/2204.08680.pdf">Paper</a>]&nbsp; [<a href="https://github.com/zengwang430521/TCFormer">Code</a>] &nbsp;[<a href="https://mp.weixin.qq.com/s/tTZqIXBhXDlSZTxjTWVQuw">Blog(商汤学术)</a>] &nbsp; [<a href="https://mp.weixin.qq.com/s/oVIHA94fR0nrOwVrflQHYw">News(机器之心)</a>]
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/PLACL-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization</h6>
                                <br>
                                Can Wang, <b>Sheng Jin</b>, Yingda Guan, Wentao Liu, Chen Qian, Ping Luo, Wanli Ouyang
                                <br>
                                <br>
                                <i>International Conference on Learning Representations (ICLR), 2022.</i>
                                <br><br>
                                [<a href="https://arxiv.org/pdf/2201.08613.pdf">Paper</a>]&nbsp;
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/MVGCN-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Graph-Based 3D Multi-Person Pose Estimation Using Multi-View Images</h6>
                                <br>
                                Size Wu, <b>Sheng Jin</b>, Wentao Liu, Lei Bai, Chen Qian, Dong Liu, Wanli Ouyang
                                <br>
                                <br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.</i>
                                <br><br>
                                [<a href="https://arxiv.org/pdf/2109.05885.pdf">Paper</a>]&nbsp; [<a href="https://github.com/open-mmlab/mmpose">Code</a>]&nbsp; [<a href="https://mp.weixin.qq.com/s/N-CQoefmPfSoafzzqGF77A">Blog(商汤学术)</a>]
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/ViPNAS-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ViPNAS: Efficient Video Pose Estimation via Neural Architecture Search</h6>
                                <br>
                                Lumin Xu, Yingda Guan, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Ping Luo, Wanli Ouyang, Xiaogang Wang
                                <br>
                                <br>
                                <i>Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i>
                                <br><br>
                                [<a href="./papers/2105.10154.pdf">Paper</a>]&nbsp; [<a href="https://github.com/luminxu/ViPNAS">Code</a>] 
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/AdvMix-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks</h6>
                                <br>
                                Jiahang Wang, <b>Sheng Jin</b>, Wentao Liu, Weizhong Liu, Chen Qian, Ping Luo
                                <br>
                                <br>
                                <i>Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i>
                                <br><br>
                                [<a href="./papers/2105.06152.pdf">Paper</a>]&nbsp; [<a href="https://github.com/AIprogrammer/AdvMix">Code</a>] 
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/FolkDuet-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>When Counterpoint Meets Chinese Folk Melodies</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Zhiyao Duan, Changshui Zhang
                                <br>
                                <br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2020. </i>
                                <br><br>
                                [<a href="./papers/NeurIPS-2020-when-counterpoint-meets-chinese-folk-melodies-Paper.pdf">Paper</a>]&nbsp;[<a href="./papers/NeurIPS-2020-when-counterpoint-meets-chinese-folk-melodies-Supp.pdf">Supplementary</a>] [<a href="./homepage_files/folkduet-poster.pdf">Poster</a>] [<a href="https://github.com/nina124/FolkDuet">Code</a>] [<a href="http://www2.ece.rochester.edu/projects/air/projects/FolkDuet.html">Project Page</a>]
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/WholeBody-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Whole-Body Human Pose Estimation in the Wild</h6>
                                <br>
                                <b>Sheng Jin</b>, Lumin Xu, Jin Xu, Can Wang, Wentao Liu, Chen Qian, Wanli Ouyang, and Ping Luo
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2020. </i>
                                <br><br>
                                [<a href="./papers/2007.11858.pdf">Paper</a>]&nbsp;[<a href="https://github.com/jin-s13/COCO-WholeBody">Dataset</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/HGG-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Differentiable Hierarchical Graph Grouping for Multi-Person Pose Estimation</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Enze Xie, Wenhai Wang, Chen Qian, Wanli Ouyang, and Ping Luo
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2020. </i>
                                <br><br>
                                [<a href="./papers/2007.11864.pdf">Paper</a>]&nbsp;[<a href="https://zhuanlan.zhihu.com/p/203083021">Blog(知乎)</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/TRB-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>TRB: A Novel Triplet Representation for Understanding 2D Human Body</h6>
                                <br>
                                Haodong Duan, Kwan-Yee Lin, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Wanli Ouyang
                                <br>
                                <br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="./papers/1910.11535">Paper</a>]&nbsp;[<a href="https://github.com/kennymckormick/Triplet-Representation-of-human-Body">Dataset</a>]
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/Rapnets-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Robust Few-Shot Learning for User-Provided Data</h6>
                                <br>
                                Jiang Lu, <b>Sheng Jin</b>, Jian Liang, and Changshui Zhang
                                <br>
                                <br>
                                <i>IEEE Transactions on Neural Networks and Learning Systems (TNNLS).</i>
                                <br><br>
                                [<a href="./papers/TNNLS_2020_Robust.pdf">Paper</a>]&nbsp;
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/RLDuet-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>RL-Duet: Online Music Accompaniment Generation Using Deep Reinforcement Learning</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Zhiyao Duan, Changshui Zhang
                                <br>
                                <br>
                                <i>AAAI Conference on Artificial Intelligence  (AAAI), 2020, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="./papers/2002.03082.pdf">Paper</a>]&nbsp;[<a href="https://drive.google.com/file/d/1Bm-iFfAcTbbjJUNq1aB8G9p3eugG5ulV/view?usp=sharing">Demo</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/PGG-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Multi-person Articulated Tracking with Spatial and Temporal Embeddings</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Wanli Ouyang, Chen Qian
                                <br>
                                <br>
                                <i>Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</i>
                                <br><br>
                                [<a href="./papers/1903.09214.pdf">Paper</a>]&nbsp;[<a href="https://youtu.be/a7qNUm0Ne7c">Demo</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/HACL-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Hierarchical Automatic Curriculum Learning: Converting a Sparse Reward Navigation Task into Dense Reward</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Changshui Zhang
                                <br><br>
                                <i>Neurocomputing, 2019.</i>
                                <br><br>
                                [<a href="./papers/Neurocomputing_2019_Jiang.pdf">Paper</a>]&nbsp;
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/EnEsCTC-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Connectionist Temporal Classification with Maximum Entropy Regularization</h6>
                                <br>
                                Hu Liu, <b>Sheng Jin</b>, Changshui Zhang
                                <br><br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2018, <font color="#e86e14">Spotlight</font>. </i>
                                <br><br>
                                [<a href="./papers/7363-connectionist-temporal-classification-with-maximum-entropy-regularization.pdf">Paper</a>]&nbsp;[<a href="./homepage_files/EnEsCTC-poster.pdf">Poster</a>]&nbsp;[<a href="https://github.com/liuhu-bigeye/enctc.crnn">Code</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/BUTD-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Towards Multi-Person Pose Tracking: Bottom-up and Top-down Methods</h6>
                                <br>
                                <b>Sheng Jin</b>, Xujie Ma, Zhipeng Han, Yue Wu, Wei Yang, Wentao Liu, Chen Qian, Wanli Ouyang
                                <br><br>
                                <i>International Conference on Computer Vision (ICCV) PoseTrack Workshop, 2017.</i>
                                <br><br>
                                [<a href="./papers/BUTD.pdf">Paper</a>]&nbsp;[<a href="https://posetrack.net/leaderboard.php">Leaderboard</a>](BUTDS and BUTD2)&nbsp;[<a href="https://www.youtube.com/watch?v=AL-8XCzRFo0">Demo</a>]
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <br>
            <br>

            <div id="projects">
                <h2>Projects</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/mmpose-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>MMPose Toolbox</h6>
                                <br>
                                <a href="https://github.com/open-mmlab/mmpose">MMPose</a> is an open-source toolbox for pose estimation based on PyTorch, which is a part of the <a href="https://github.com/open-mmlab">OpenMMLab</a> project.
                                <br><br>
                                [<a href="https://github.com/open-mmlab/mmpose">Project</a>]&nbsp;<iframe src="https://img.shields.io/github/stars/open-mmlab/mmpose?style=social" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/hieve.gif"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ACM MM'2020 HiEve Challenge</h6>
                                <br>
                                Our team (SimpleTrack) won the <b>3rd place</b> in Track-3 "Crowd Pose Tracking in Complex Events" of <a href="http://humaninevents.org/ACM_welcome.html">ACM MM'2020 HiEve Challenge</a>.
                                <br><br>
                                [<a href="http://humaninevents.org/ACM_oltp.html?title=4">Leaderboard</a>]&nbsp;[<a href="https://dl.acm.org/doi/10.1145/3394171.3416295">Technical Report</a>]
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/lip.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>CVPR'2018 Look Into Person (LIP) Challenge</h6>
                                <br>
                                Our team (MJDG) won the <b>2nd place</b> in Track-4 "Multi-Human Pose Estimation Challenge" of <a href="https://vuhcs.github.io/vuhcs-2018/index.html">CVPR'2018 LIP Challenge</a>.
                                <br><br>
                                [<a href="https://lv-mhp.github.io/pose_estimation_lb">Leaderboard</a>]&nbsp;[<a href="./papers/CVPR18_MHP_Slides.pdf">Oral Presentation</a>] &nbsp;
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/posetrack.gif"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ICCV'2017 PoseTrack Challenge</h6>
                                <br>
                                Our team (BUTDS | BUTD2) won the <b>2nd places</b> in both Track-1 "Single-Frame Person Pose Estimation" and Track-3 "Multi-Person Pose Tracking" of <a href="https://posetrack.net/workshops/iccv2017/">ICCV'2017 PoseTrack Challenge</a>.
                                <br><br>
                                [<a href="https://posetrack.net/leaderboard.php">Leaderboard</a>]&nbsp;[<a href="./papers/BUTD.pdf">Technical Report</a>] &nbsp;[<a href="./papers/ICCV17_PoseTrack_Slides.pdf">Oral Presentation</a>] &nbsp;[<a href="https://www.youtube.com/watch?v=AL-8XCzRFo0">Demo</a>]
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <br>
            <br>

            <div id="patent">
                <h2>Patents</h2>
                    <details>
                    <summary>Click to expand or collapse</summary>
                    <table class="table-pub">
                         <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN111898642A. Publication Date: 2020-11-06.
                                </div>
                            </td>
                        </tr>
                         <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN111783882A. Publication Date: 2020-10-16.
                                </div>
                            </td>
                        </tr>
                         <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Image processing method and device, detection device and storage medium</h6>
                                    <br>
                                    Tong Li, <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN111539992A. Publication Date: 2020-08-14.
                                </div>
                            </td>
                        </tr>
                         <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN111444928A. Publication Date: 2020-07-24.
                                </div>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Image processing method and device, detection device and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN109948526A. Publication Date: 2019-06-28.
                                </div>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Image processing method and device, detection device and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN109934183A. Publication Date: 2019-06-25.
                                </div>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <div class="pub-info">
                                    <h6>Deep learning model training method and device, training equipment and storage medium</h6>
                                    <br>
                                    <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                    <br><br>
                                    Chinese Invention Patent.
                                    <br><br>
                                    Publication Number: CN109919245A. Publication Date: 2019-06-21.
                                </div>
                            </td>
                        </tr>
                    </table>
                </details>
            </div>

            <br>
            <br>

            <div id="activities">
                <h2>Activities</h2>
                <br>
                <li>Conference Reviewer/PC Member</li>
                    <ul>
                        NeurIPS'19, AAAI'19, NeurIPS'20, ICML'20, CVPR'20, AAAI'21, WACV'21, ICLR'21, ICML'21, CVPR'21, ICCV'21
                    </ul>
                <li>Journal Reviewer</li>
                    <ul>
                        IEEE Transactions on Artificial Intelligence (TAI), Transactions on Image Processing (TIP), International Journal of Computer Vision (IJCV)
                    </ul>
                <li>Website Chairs</li>
                    <ul>
                        <a href="http://bigeye.au.tsinghua.edu.cn/sidas2017/">IEEE SPS SIDAS 2017 Forum</a>
                    </ul>
            </div>

            <br>
            <br>

            <div id="contacts">
                <h2>Contacts</h2>
                <i class="fa fa-envelope"></i> js20 [at] connect.hku.hk  | jinsheng13 [at] foxmail.com
            </div>
                
            <div class="col-md-3 text-center">
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=tt&d=amNpZ1mr8noV_wMpMl2UPDW_8iZ7-FTLlK3f_zuftUc&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
            </div>
                
        </div>
        <div class="clear"></div>
    </div>


</body>

</html>
