
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Sheng Jin; Computer Vision; Deep Learning; Human Pose Estimation; The University of Hong Kong; Tsinghua University; SenseTime">
    <link rel="author" href="https://jin-s13.github.io/">
    <title>Sheng Jin's Homepage</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-177752133-1', 'https://jin-s13.github.io');
  ga('send', 'pageview');
</script>

<body>
    <div id="container">
        <div id="header">
            <h1><a href="#">Sheng Jin</a></h1>
            <br>
            <div class="clear"></div>
        </div>
        
        <div id="body">
            <div id="aboutme">
                <h2>About Me</h2>
                <table class="table-bio">
                    <td class="col-7">
                    <p>
                        Sheng Jin is currently a Phd candidate (2020-present) at the University of Hong Kong (HKU), advised by Dr. <a href="http://luoping.me/">Ping Luo</a> and co-supervised by Prof. <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a>. 
                        He is also a part-time researcher (2020-present) at <a href="https://www.sensetime.com/?lang=en-us">SenseTime Research</a> mentored by Dr. Wentao Liu.
                        <br>
                        <br>
                        In 2020, he received his master's degree in the Department of Automation at Tsinghua University, advised by Prof. <a href="https://scholar.google.com/citations?user=GL9M37YAAAAJ&hl=en">Changshui Zhang</a>.
                        In 2017, he received the B.Eng. degree with highest honor (Outstanding Graduate Scholarships) from Tsinghua University.
                        <br>
                        <br>
                        His research focus is on teaching machines/robots to see and understand human behaviors such as human body poses, actions, and human-machine interactions.
                    </p>
                    </td>
                    <td class="col-3">
                        <img src="./homepage_files/me.png">
                    </td>
                </table>
            </div>


            <div id="news">
                <h2>News</h2>
                <br>
                    <ul>
                        <li><font color="ff0000"> <strong><em>We are recruiting intern researchers in computer vision at SenseTime Research (Beijing). If you are interested in, please send your CV to my email.</em></strong></font></li>
                        <br>
                        <li>[2020-09] One paper accepted by NeurIPS'2020.</li>
                        <br>
                        <li>[2020-08] We have released <a href="https://github.com/open-mmlab/mmpose">MMPose</a> Toolbox v0.6.</li>    
                        <br>
                        <li>[2020-07] Two papers accepted by ECCV'2020.</li>       
                        <br>
                        <li>[2020-06] Our team won the 3rd place of <a href="http://humaninevents.org/ACM_welcome.html">ACM MM'2020 HiEve Challenge</a> (<a href="http://humaninevents.org/ACM_oltp.html?title=4">Leaderboard</a>: SimpleTrack).
                        <br>
                        <br>
                        <li>[2020-04] One paper accepted by TNNLS.</li>
                        <br>
                        <li>[2020-02] One paper accepted by AAAI'2020 <font color="#e86e14">(Oral)</font>.</li>    
                        <br>
                        <li>[2019-10] One paper accepted by ICCV'2019.</li>  
                        <br>
                        <li>[2019-06] One paper accepted by CVPR'2019.</li>  
                        <br>
                        <li>[2018-12] One paper accepted by NeurIPS'2018 <font color="#e86e14">(Spotlight)</font>.</li>  
                        <br>
                        <li>[2018-04] Our team won the 2nd places of the <a href="https://vuhcs.github.io/vuhcs-2018/index.html">CVPR'2018 LIP Challenge</a> (<a href="https://lv-mhp.github.io/pose_estimation_lb">Leaderboard</a>: MJDG).</li>
                        <br>
                        <li>[2017-10] Our team won the 2nd places of the <a href="https://posetrack.net/workshops/iccv2017/">ICCV'2017 PoseTrack Challenge</a> (<a href="https://posetrack.net/workshops/iccv2017/pdfs/BUTD.pdf">Technical Report</a> | <a href="https://posetrack.net/leaderboard.php">Leaderboard</a>: BUTDS and BUTD2 | <a href="https://www.youtube.com/watch?v=AL-8XCzRFo0">Demo</a>).</li>
                        <br>
                    </ul>
            </div>


            <div id="education">
                <h2>Education</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/hku.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>The University of Hong Kong</h6>
                                <br>
                                PhD in Computer Science (HKPFS awardee), 2020~now
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/thu.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Tsinghua University</h6>
                                <br>
                                 MS in Control Science and Engineering, 2017~2020
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-1"><a href=""><img src="./homepage_files/thu.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Tsinghua University</h6>
                                <br>
                                BSc in Automation (ranking 1/145), 2013~2017
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <br>
            <br>

            <div class="container">
                <h2>Honors and Awards</h2>
                <div>
                    <ul>
                        <li><b>Hong Kong PhD Fellowships (HKPF)</b>, 2020.</li>
                        <br>
                        <li><b>Outstanding Graduate Scholarship</b>, Tsinghua University (top 1% in Tsinghua), 2017.</li>
                        <br>
                        <li><b>The Baosteel Excellent Student Scholarship</b>, 2016.</li>
                        <br>
                        <li>Zheng Weimin Scholarship (2nd class) for Comprehensive Excellence, 2016.</li>
                        <br>
                        <li>Tsinghua-JJWorld (Beijing) Nework Technology Fellowships, Tsinghua University, 2015.</li>
                        <br>
                        <li>Tsinghua-Evergrande Fellowships for Academic Excellence, Tsinghua University, 2014.</li>
                    </ul>
                </div>
            </div>
            
            <br>
            <br>

            <div id="publication">
                <h2>Selected Publications</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/FolkDuet-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>When Counterpoint Meets Chinese Folk Melodies</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Zhiyao Duan, Changshui Zhang
                                <br>
                                <br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2020. </i>
                                <br><br>
                                [<a href="./papers/NeurIPS-2020-when-counterpoint-meets-chinese-folk-melodies-Paper.pdf">Paper</a>]&nbsp;[<a href="./papers/NeurIPS-2020-when-counterpoint-meets-chinese-folk-melodies-Supp.pdf">Supplementary</a>]&nbsp;[<a href="./homepage_files/folkduet-poster.pdf">Poster</a>]
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/WholeBody-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Whole-Body Human Pose Estimation in the Wild</h6>
                                <br>
                                <b>Sheng Jin</b>, Lumin Xu, Jin Xu, Can Wang, Wentao Liu, Chen Qian, Wanli Ouyang, and Ping Luo
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2020. </i>
                                <br><br>
                                [<a href="./papers/2007.11858.pdf">Paper</a>]&nbsp;[<a href="https://github.com/jin-s13/COCO-WholeBody">Dataset</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/HGG-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Differentiable Hierarchical Graph Grouping for Multi-Person Pose Estimation</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Enze Xie, Wenhai Wang, Chen Qian, Wanli Ouyang, and Ping Luo
                                <br>
                                <br>
                                <i>European Conference on Computer Vision (ECCV), 2020. </i>
                                <br><br>
                                [<a href="./papers/2007.11864.pdf">Paper</a>]&nbsp;[<a href="https://zhuanlan.zhihu.com/p/203083021">Blog</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/TRB-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>TRB: A Novel Triplet Representation for Understanding 2D Human Body</h6>
                                <br>
                                Haodong Duan, Kwan-Yee Lin, <b>Sheng Jin</b>, Wentao Liu, Chen Qian, Wanli Ouyang
                                <br>
                                <br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="./papers/1910.11535">Paper</a>]&nbsp;[<a href="https://github.com/kennymckormick/Triplet-Representation-of-human-Body">Dataset</a>]
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/Rapnets-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Robust Few-Shot Learning for User-Provided Data</h6>
                                <br>
                                Jiang Lu, <b>Sheng Jin</b>, Jian Liang, and Changshui Zhang
                                <br>
                                <br>
                                <i>IEEE Transactions on Neural Networks and Learning Systems (TNNLS).</i>
                                <br><br>
                                [<a href="./papers/TNNLS_2020_Robust.pdf">Paper</a>]&nbsp;
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/RLDuet-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>RL-Duet: Online Music Accompaniment Generation Using Deep Reinforcement Learning</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Zhiyao Duan, Changshui Zhang
                                <br>
                                <br>
                                <i>AAAI Conference on Artificial Intelligence  (AAAI), 2020, <font color="#e86e14">Oral</font>.</i>
                                <br><br>
                                [<a href="./papers/2002.03082.pdf">Paper</a>]&nbsp;[<a href="https://drive.google.com/file/d/1Bm-iFfAcTbbjJUNq1aB8G9p3eugG5ulV/view?usp=sharing">Demo</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/PGG-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Multi-person Articulated Tracking with Spatial and Temporal Embeddings</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Wanli Ouyang, Chen Qian
                                <br>
                                <br>
                                <i>Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</i>
                                <br><br>
                                [<a href="./papers/1903.09214.pdf">Paper</a>]&nbsp;[<a href="https://youtu.be/a7qNUm0Ne7c">Demo</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/HACL-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Hierarchical Automatic Curriculum Learning: Converting a Sparse Reward Navigation Task into Dense Reward</h6>
                                <br>
                                Nan Jiang, <b>Sheng Jin</b>, Changshui Zhang
                                <br><br>
                                <i>Neurocomputing, 2019.</i>
                                <br><br>
                                [<a href="./papers/Neurocomputing_2019_Jiang.pdf">Paper</a>]&nbsp;
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/EnEsCTC-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Connectionist Temporal Classification with Maximum Entropy Regularization</h6>
                                <br>
                                Hu Liu, <b>Sheng Jin</b>, Changshui Zhang
                                <br><br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2018, <font color="#e86e14">Spotlight</font>. </i>
                                <br><br>
                                [<a href="./papers/7363-connectionist-temporal-classification-with-maximum-entropy-regularization.pdf">Paper</a>]&nbsp;[<a href="./homepage_files/EnEsCTC-poster.pdf">Poster</a>]&nbsp;[<a href="https://github.com/liuhu-bigeye/enctc.crnn">Code</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/BUTD-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Towards Multi-Person Pose Tracking: Bottom-up and Top-down Methods</h6>
                                <br>
                                <b>Sheng Jin</b>, Xujie Ma, Zhipeng Han, Yue Wu, Wei Yang, Wentao Liu, Chen Qian, Wanli Ouyang
                                <br><br>
                                <i>International Conference on Computer Vision (ICCV) PoseTrack Workshop, 2017.</i>
                                <br><br>
                                [<a href="./papers/BUTD.pdf">Paper</a>]&nbsp;[<a href="https://posetrack.net/leaderboard.php">Leaderboard</a>](BUTDS and BUTD2)&nbsp;[<a href="https://www.youtube.com/watch?v=AL-8XCzRFo0">Demo</a>]
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <div id="projects">
                <h2>Projects</h2>
                <table class="table-pub">
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/mmpose-logo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>MMPose Toolbox</h6>
                                <br>
                                <a href="https://github.com/open-mmlab/mmpose">MMPose</a> is an open-source toolbox for pose estimation based on PyTorch, which is a part of the <a href="https://github.com/open-mmlab">OpenMMLab</a> project.
                                <br><br>
                                [<a href="https://github.com/open-mmlab/mmpose">Project</a>]&nbsp;
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/hieve.gif"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ACM MM'2020 HiEve Challenge</h6>
                                <br>
                                Our team (SimpleTrack) won the <b>3rd place</b> in Track-3 "Crowd Pose Tracking in Complex Events" of <a href="http://humaninevents.org/ACM_welcome.html">ACM MM'2020 HiEve Challenge</a>.
                                <br><br>
                                [<a href="http://humaninevents.org/ACM_oltp.html?title=4">Leaderboard</a>]&nbsp;
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/lip.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>CVPR'2018 Look Into Person (LIP) Challenge</h6>
                                <br>
                                Our team (MJDG) won the <b>2nd place</b> in Track-4 "Multi-Human Pose Estimation Challenge" of <a href="https://vuhcs.github.io/vuhcs-2018/index.html">CVPR'2018 LIP Challenge</a>.
                                <br><br>
                                [<a href="https://lv-mhp.github.io/pose_estimation_lb">Leaderboard</a>]&nbsp;[<a href="./papers/CVPR18_MHP_Slides.pdf">Oral Presentation</a>] &nbsp;
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-3"><a href=""><img src="./homepage_files/posetrack.gif"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ICCV'2017 PoseTrack Challenge</h6>
                                <br>
                                Our team (BUTDS | BUTD2) won the <b>2nd places</b> in both Track-1 "Single-Frame Person Pose Estimation" and Track-3 "Multi-Person Pose Tracking" of <a href="https://posetrack.net/workshops/iccv2017/">ICCV'2017 PoseTrack Challenge</a>.
                                <br><br>
                                [<a href="https://posetrack.net/leaderboard.php">Leaderboard</a>]&nbsp;[<a href="./papers/BUTD.pdf">Technical Report</a>] &nbsp;[<a href="./papers/ICCV17_PoseTrack_Slides.pdf">Oral Presentation</a>] &nbsp;[<a href="https://www.youtube.com/watch?v=AL-8XCzRFo0">Demo</a>]
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <div id="patent">
                <h2>Pantent</h2>
                <table class="table-pub">
                     <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN111898642A. Publication Date: 2020-11-06.
                            </div>
                        </td>
                    </tr>
                     <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN111783882A. Publication Date: 2020-10-16.
                            </div>
                        </td>
                    </tr>
                     <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Image processing method and device, detection device and storage medium</h6>
                                <br>
                                Tong Li, <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN111539992A. Publication Date: 2020-08-14.
                            </div>
                        </td>
                    </tr>
                     <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Key point detection method, device, electronic equipment and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN111444928A. Publication Date: 2020-07-24.
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Image processing method and device, detection device and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN109948526A. Publication Date: 2019-06-28.
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Image processing method and device, detection device and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN109934183A. Publication Date: 2019-06-25.
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <div class="pub-info">
                                <h6>Deep learning model training method and device, training equipment and storage medium</h6>
                                <br>
                                <b>Sheng Jin</b>, Wentao Liu, Chen Qian
                                <br><br>
                                Chinese Invention Patent.
                                <br><br>
                                Publication Number: CN109919245A. Publication Date: 2019-06-21.
                            </div>
                        </td>
                    </tr>
                </table>
            </div>

            <div id="activities">
                <h2>Activities</h2>
                <br>
                <li>Reviewer/PC Member</li>
                    <ul>
                        NeurIPS'19, AAAI'19, NeurIPS'20, ICML'20, CVPR'20, AAAI'21, WACV'21, ICLR'21, ICML'21, CVPR'21
                    </ul>
                <li>Website Chairs</li>
                    <ul>
                        <a href="http://bigeye.au.tsinghua.edu.cn/sidas2017/">IEEE SPS SIDAS 2017 Forum</a>
                    </ul>
            </div>

            <div id="contacts">
                <h2>Contacts</h2>
                <i class="fa fa-envelope"></i> js20 at connect.hku.hk  | jinsheng [at] sensetime.com 
            </div>
                
            <div class="col-md-3 text-center">
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=tt&d=amNpZ1mr8noV_wMpMl2UPDW_8iZ7-FTLlK3f_zuftUc&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
            </div>
                
        </div>
        <div class="clear"></div>
    </div>


</body>

</html>
